{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy import loadtxt, where\n",
    "from pylab import scatter, show, legend, xlabel, ylabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scale larger positive and values to between -1,1 depending on the largest\n",
    "# value in the data\n",
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(-1,1))\n",
    "df = pd.read_csv(\"logisticRegression2.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clean up data\n",
    "df.columns = [\"L\",\"D\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# formats the input data into two arrays, one of independant variables\n",
    "# and one of the dependant variable\n",
    "X = df[[\"L\"]]\n",
    "X = np.array(X)\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "\n",
    "Y = df[\"D\"]\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating testing and training set\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score Scikit learn:  0.722222222222\n"
     ]
    }
   ],
   "source": [
    "# train scikit learn model \n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train,Y_train)\n",
    "print 'score Scikit learn: ', clf.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.6765\n",
      "test accuracy: 0.7222\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %4.4f' % clf.score(X_train, Y_train))\n",
    "print('test accuracy: %4.4f' % clf.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cvs = cross_val_score(clf, X, Y, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('k =', 1, ', model accuracy: 0.7143')\n",
      "('k =', 2, ', model accuracy: 0.4286')\n",
      "('k =', 3, ', model accuracy: 0.7143')\n",
      "('k =', 4, ', model accuracy: 0.7143')\n",
      "('k =', 5, ', model accuracy: 0.5000')\n",
      "('k =', 6, ', model accuracy: 0.6667')\n",
      "('k =', 7, ', model accuracy: 0.8333')\n",
      "('k =', 8, ', model accuracy: 0.6667')\n"
     ]
    }
   ],
   "source": [
    "k = 1\n",
    "for score in cvs:\n",
    "    print ('k =', k, ', model accuracy: %4.4f' % score)\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##The sigmoid function adjusts the cost function hypotheses to adjust the algorithm proportionally for worse estimations\n",
    "def Sigmoid(z):\n",
    "    G_of_Z = float(1.0 / float((1.0 + math.exp(-1.0*z))))\n",
    "    return G_of_Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##The hypothesis is the linear combination of all the known factors x[i] and their current estimated coefficients theta[i] \n",
    "##This hypothesis will be used to calculate each instance of the Cost Function\n",
    "def Hypothesis(theta, x):\n",
    "    z = 0\n",
    "    for i in xrange(len(theta)):\n",
    "        z += x[i]*theta[i]\n",
    "    return Sigmoid(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
